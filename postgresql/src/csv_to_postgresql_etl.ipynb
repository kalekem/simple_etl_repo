{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b97167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import numpy as np \n",
    "import psycopg2.extras as extras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b01d10",
   "metadata": {},
   "source": [
    "CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d5f20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_FILE = '../data/sales.csv'\n",
    "DB_NAME = 'sales_db'\n",
    "DB_USER = '<user_name>'\n",
    "DB_PASSWORD = '<password>' \n",
    "DB_HOST = 'localhost'\n",
    "DB_PORT = '5432'\n",
    "TARGET_TABLE = 'etl_transformed_sales'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45dc3a5",
   "metadata": {},
   "source": [
    "DB CONNECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5a97a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establish Connection to PostgreSQL Database\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD,\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT\n",
    "    )\n",
    "    print(f\"Successfully connected to PostgreSQL database: {DB_NAME}\")\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Database connection failed. Error: {e}\")\n",
    "    print(\"Please check your database service and credentials.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a473a3c2",
   "metadata": {},
   "source": [
    "CREATE TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1fb6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the target table structure in PostgreSQL if it doesn't exist\n",
    "create_table_query = sql.SQL(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {TARGET_TABLE}(\n",
    "            order_id INTEGER UNIQUE,\n",
    "            product VARCHAR(255),\n",
    "            category VARCHAR(100),\n",
    "            sales_amount NUMERIC(10, 2),\n",
    "            order_date DATE,\n",
    "            region VARCHAR(50),\n",
    "            customer_name VARCHAR(255),\n",
    "            unit_price NUMERIC(10, 2), -- Transformed column\n",
    "            sales_tier VARCHAR(50),     -- Transformed column\n",
    "            load_timestamp TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n",
    "        );\n",
    "    \"\"\")\n",
    "\n",
    "try:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(create_table_query)\n",
    "        conn.commit()\n",
    "    print(f\"Table '{TARGET_TABLE}' already exists or has been successully created!\")\n",
    "except psycopg2.Error as e:\n",
    "    print(f\" Error creating table: {e}\")\n",
    "    conn.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc26030",
   "metadata": {},
   "source": [
    "EXTRACT (E) STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a14e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Data (E)\n",
    "print(\"---Step 1: Extraction (E) ---\")\n",
    "\n",
    "try:\n",
    "    # Read the CSV file into a Pandas DataFrame\n",
    "    df = pd.read_csv(CSV_FILE)\n",
    "    print(f\"Data extracted successfully from '{CSV_FILE}'.\")\n",
    "    print(f\"Initial DataFrame shape: {df.shape}\")\n",
    "    print(\"\\nInitial Data Head:\")\n",
    "    display(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\" Error: The file '{CSV_FILE}' was not found. Make sure it's in the same directory.\")\n",
    "    df = None\n",
    "except Exception as e:\n",
    "    print(f\" Error during CSV read: {e}\")\n",
    "    df = None\n",
    "\n",
    "if df is None:\n",
    "    raise SystemExit(\"Exiting ETL process due to extraction failure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c46a771",
   "metadata": {},
   "source": [
    "TRANSFORM (T) STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f729e11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. TRANSFORMATION (T) ---\n",
    "print(\"\\n--- Step 2: Transformation (T) ---\")\n",
    "\n",
    "# T1: Clean column names (lowercase and replace spaces/special chars)\n",
    "df.columns = df.columns.str.replace(' ', '_').str.replace(r'([A-Z])', r'_\\1', regex=True).str.lower().str.strip('_')\n",
    "print(\"Column names cleaned.\")\n",
    "print(f\"New Columns: {df.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9811af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T2: Data Type Conversion\n",
    "# Convert OrderDate to datetime objects\n",
    "df['order_date'] = pd.to_datetime(df['order_date'])\n",
    "# Ensure SalesAmount is numeric (it should be, but good practice)\n",
    "df['sales_amount'] = pd.to_numeric(df['sales_amount'])\n",
    "print(\"Data types adjusted (OrderDate to datetime, SalesAmount to numeric).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c74929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T3: Derived Column Creation (Unit Price)\n",
    "# For this simple example, we'll assume every sale is for exactly 1 unit.\n",
    "df['unit_price'] = df['sales_amount']\n",
    "print(\"Derived column 'unit_price' created (assuming quantity=1).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defed67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T4: Categorical Transformation (Creating a Sales Tier based on amount)\n",
    "\n",
    "# 1. Define the list of conditions (must be Boolean arrays/Series)\n",
    "conditions = [\n",
    "    df['sales_amount'] >= 500,\n",
    "    df['sales_amount'] >= 100\n",
    "]\n",
    "\n",
    "# 2. Define the list of values corresponding to the conditions\n",
    "choices = [\n",
    "    'High Value',\n",
    "    'Medium Value'\n",
    "]\n",
    "\n",
    "# 3. Apply np.select: The \"default\" argument handles all cases that don't meet the conditions (i.e., less than 100)\n",
    "df['sales_tier'] = np.select(conditions, choices, default='Low Value')\n",
    "\n",
    "print(\"Categorical transformation 'sales_tier' created using np.select.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a10612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T5: Filtering (Basic Data Quality Check)\n",
    "# Remove rows where SalesAmount is less than or equal to 0\n",
    "initial_rows = len(df)\n",
    "df = df[df['sales_amount'] > 0]\n",
    "rows_removed = initial_rows - len(df)\n",
    "print(f\" Data filtered: Removed {rows_removed} rows with non-positive sales amounts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418f6a41",
   "metadata": {},
   "source": [
    "LOAD (L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699ac3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load = df[[\n",
    "    'order_id', 'product', 'category', 'sales_amount', 'order_date',\n",
    "    'region', 'customer_name', 'unit_price', 'sales_tier'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f152bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame to a list of tuples for psycopg2's execute_batch\n",
    "data_tuples = [tuple(row) for row in df_load.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c54a9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the INSERT query structure\n",
    "cols = ', '.join(df_load.columns)\n",
    "placeholders = ', '.join(['%s'] * len(df_load.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd692aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns to update (all except the unique key 'order_id')\n",
    "update_cols = [col for col in df_load.columns if col not in ['order_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3493a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_clause = ', '.join([f\"{col} = EXCLUDED.{col}\" for col in update_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c742dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_query = sql.SQL(\n",
    "    f\"\"\"\n",
    "    INSERT INTO {TARGET_TABLE} ({cols}) \n",
    "    VALUES ({placeholders}) \n",
    "    ON CONFLICT (order_id) \n",
    "    DO UPDATE SET {set_clause}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679d304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with conn.cursor() as cur:\n",
    "        # Use execute_batch for efficient bulk insertion\n",
    "        extras.execute_batch(cur, insert_query, data_tuples)\n",
    "        conn.commit()\n",
    "        print(f\"Successfully attempted to load {len(data_tuples)} records into '{TARGET_TABLE}'. Conflicting records were updated.\")\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error during data loading: {e}\")\n",
    "    conn.rollback()\n",
    "\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()\n",
    "        print(\" Database connection closed.\")\n",
    "\n",
    "print(\"\\n--- ETL Process Complete ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etl_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
